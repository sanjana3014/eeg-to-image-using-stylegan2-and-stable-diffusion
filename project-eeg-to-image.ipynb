{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15cbb44",
   "metadata": {
    "papermill": {
     "duration": 0.007457,
     "end_time": "2025-07-24T05:41:31.162408",
     "exception": false,
     "start_time": "2025-07-24T05:41:31.154951",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794dd4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:41:31.176815Z",
     "iopub.status.busy": "2025-07-24T05:41:31.176118Z",
     "iopub.status.idle": "2025-07-24T05:42:43.345782Z",
     "shell.execute_reply": "2025-07-24T05:42:43.344875Z"
    },
    "papermill": {
     "duration": 72.178306,
     "end_time": "2025-07-24T05:42:43.347305",
     "exception": false,
     "start_time": "2025-07-24T05:41:31.168999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-msssim\r\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-msssim) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch-msssim)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-msssim) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-msssim) (3.0.2)\r\n",
      "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-msssim\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-msssim-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc77e088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:42:43.404130Z",
     "iopub.status.busy": "2025-07-24T05:42:43.403878Z",
     "iopub.status.idle": "2025-07-24T05:42:43.407477Z",
     "shell.execute_reply": "2025-07-24T05:42:43.406837Z"
    },
    "papermill": {
     "duration": 0.033151,
     "end_time": "2025-07-24T05:42:43.408692",
     "exception": false,
     "start_time": "2025-07-24T05:42:43.375541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/lucidrains/stylegan2-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d4be01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:42:43.464673Z",
     "iopub.status.busy": "2025-07-24T05:42:43.464369Z",
     "iopub.status.idle": "2025-07-24T05:42:47.724269Z",
     "shell.execute_reply": "2025-07-24T05:42:47.723470Z"
    },
    "papermill": {
     "duration": 4.289424,
     "end_time": "2025-07-24T05:42:47.726018",
     "exception": false,
     "start_time": "2025-07-24T05:42:43.436594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan2-pytorch'...\r\n",
      "remote: Enumerating objects: 395, done.\u001b[K\r\n",
      "remote: Total 395 (delta 0), reused 0 (delta 0), pack-reused 395 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (395/395), 122.51 MiB | 45.45 MiB/s, done.\r\n",
      "Resolving deltas: 100% (205/205), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rosinality/stylegan2-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f639af92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:42:47.832303Z",
     "iopub.status.busy": "2025-07-24T05:42:47.831630Z",
     "iopub.status.idle": "2025-07-24T05:43:04.587044Z",
     "shell.execute_reply": "2025-07-24T05:43:04.586259Z"
    },
    "papermill": {
     "duration": 16.833182,
     "end_time": "2025-07-24T05:43:04.588623",
     "exception": false,
     "start_time": "2025-07-24T05:42:47.755441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-24 05:42:47--  https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl\r\n",
      "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 3.163.158.113, 3.163.158.83, 3.163.158.75, ...\r\n",
      "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|3.163.158.113|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 381673535 (364M) [application/x-www-form-urlencoded]\r\n",
      "Saving to: ‘stylegan2_ffhq.pkl’\r\n",
      "\r\n",
      "stylegan2_ffhq.pkl  100%[===================>] 363.99M  25.4MB/s    in 16s     \r\n",
      "\r\n",
      "2025-07-24 05:43:04 (23.3 MB/s) - ‘stylegan2_ffhq.pkl’ saved [381673535/381673535]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl -O stylegan2_ffhq.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee09e8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:43:04.651430Z",
     "iopub.status.busy": "2025-07-24T05:43:04.651165Z",
     "iopub.status.idle": "2025-07-24T05:44:18.970421Z",
     "shell.execute_reply": "2025-07-24T05:44:18.969360Z"
    },
    "papermill": {
     "duration": 74.351959,
     "end_time": "2025-07-24T05:44:18.972122",
     "exception": false,
     "start_time": "2025-07-24T05:43:04.620163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/_weights_only_unpickler.py:529: UserWarning: Detected pickle protocol 4 in the checkpoint, which was not the default pickle protocol used by `torch.load` (2). The weights_only Unpickler might not support all instructions implemented by this protocol, please file an issue for adding support if you encounter this.\r\n",
      "  warnings.warn(\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/stylegan2-pytorch/generate.py\", line 74, in <module>\r\n",
      "    checkpoint = torch.load(args.ckpt)\r\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1494, in load\r\n",
      "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\r\n",
      "_pickle.UnpicklingError: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\r\n",
      "Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\r\n",
      "\r\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\r\n"
     ]
    }
   ],
   "source": [
    " !python stylegan2-pytorch/generate.py --size 1024 --ckpt stylegan2_ffhq.pkl --sample 1 --pics 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c759439d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:19.034906Z",
     "iopub.status.busy": "2025-07-24T05:44:19.034638Z",
     "iopub.status.idle": "2025-07-24T05:44:37.900799Z",
     "shell.execute_reply": "2025-07-24T05:44:37.900025Z"
    },
    "papermill": {
     "duration": 18.899111,
     "end_time": "2025-07-24T05:44:37.902388",
     "exception": false,
     "start_time": "2025-07-24T05:44:19.003277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stylegan2_pytorch\r\n",
      "  Downloading stylegan2_pytorch-1.9.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting aim (from stylegan2_pytorch)\r\n",
      "  Downloading aim-3.29.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (0.8.1)\r\n",
      "Collecting contrastive_learner>=0.1.0 (from stylegan2_pytorch)\r\n",
      "  Downloading contrastive_learner-0.1.1-py3-none-any.whl.metadata (638 bytes)\r\n",
      "Collecting fire (from stylegan2_pytorch)\r\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: kornia>=0.5.4 in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (0.8.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (1.26.4)\r\n",
      "Collecting retry (from stylegan2_pytorch)\r\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (4.67.1)\r\n",
      "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stylegan2_pytorch) (11.2.1)\r\n",
      "Collecting vector-quantize-pytorch==0.1.0 (from stylegan2_pytorch)\r\n",
      "  Downloading vector_quantize_pytorch-0.1.0.tar.gz (2.2 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.11/dist-packages (from kornia>=0.5.4->stylegan2_pytorch) (0.1.9)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia>=0.5.4->stylegan2_pytorch) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->stylegan2_pytorch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2->stylegan2_pytorch) (1.3.0)\r\n",
      "Collecting aim-ui==3.29.1 (from aim->stylegan2_pytorch)\r\n",
      "  Downloading aim-ui-3.29.1.tar.gz (31.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting aimrecords==0.0.7 (from aim->stylegan2_pytorch)\r\n",
      "  Downloading aimrecords-0.0.7-py2.py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting aimrocks==0.5.* (from aim->stylegan2_pytorch)\r\n",
      "  Downloading aimrocks-0.5.2-cp311-cp311-manylinux_2_24_x86_64.whl.metadata (580 bytes)\r\n",
      "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (5.5.2)\r\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (8.2.1)\r\n",
      "Requirement already satisfied: cryptography>=3.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (44.0.3)\r\n",
      "Requirement already satisfied: psutil>=5.6.7 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (7.0.0)\r\n",
      "Collecting RestrictedPython>=5.1 (from aim->stylegan2_pytorch)\r\n",
      "  Downloading RestrictedPython-8.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: aiofiles>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (22.1.0)\r\n",
      "Requirement already satisfied: alembic<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (1.16.2)\r\n",
      "Requirement already satisfied: fastapi<1,>=0.69.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (0.115.13)\r\n",
      "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (2025.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (2.0.41)\r\n",
      "Requirement already satisfied: uvicorn<1,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (0.34.3)\r\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (2.9.0.post0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (2.32.4)\r\n",
      "Requirement already satisfied: watchdog in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (6.0.0)\r\n",
      "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (15.0.1)\r\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from aim->stylegan2_pytorch) (1.39.1)\r\n",
      "Collecting base58==2.0.1 (from aimrecords==0.0.7->aim->stylegan2_pytorch)\r\n",
      "  Downloading base58-2.0.1-py3-none-any.whl.metadata (540 bytes)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->stylegan2_pytorch) (2.4.1)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->stylegan2_pytorch) (3.1.0)\r\n",
      "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry->stylegan2_pytorch) (4.4.2)\r\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry->stylegan2_pytorch)\r\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2,>=1.5.0->aim->stylegan2_pytorch) (1.3.10)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0->aim->stylegan2_pytorch) (1.17.1)\r\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (0.46.2)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (2.11.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->stylegan2_pytorch) (3.0.2)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.1->aim->stylegan2_pytorch) (3.2.3)\r\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1,>=0.12.0->aim->stylegan2_pytorch) (0.16.0)\r\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.1 in /usr/local/lib/python3.11/dist-packages (from boto3->aim->stylegan2_pytorch) (1.39.1)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->aim->stylegan2_pytorch) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->aim->stylegan2_pytorch) (0.13.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->stylegan2_pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->stylegan2_pytorch) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->stylegan2_pytorch) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->stylegan2_pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->aim->stylegan2_pytorch) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->aim->stylegan2_pytorch) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->aim->stylegan2_pytorch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->aim->stylegan2_pytorch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->aim->stylegan2_pytorch) (2025.6.15)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0->aim->stylegan2_pytorch) (2.22)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->stylegan2_pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (0.4.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (4.9.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1,>=0.69.0->aim->stylegan2_pytorch) (1.3.1)\r\n",
      "Downloading stylegan2_pytorch-1.9.0-py3-none-any.whl (19 kB)\r\n",
      "Downloading contrastive_learner-0.1.1-py3-none-any.whl (4.9 kB)\r\n",
      "Downloading aim-3.29.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aimrecords-0.0.7-py2.py3-none-any.whl (28 kB)\r\n",
      "Downloading aimrocks-0.5.2-cp311-cp311-manylinux_2_24_x86_64.whl (6.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading base58-2.0.1-py3-none-any.whl (4.3 kB)\r\n",
      "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\r\n",
      "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading RestrictedPython-8.0-py3-none-any.whl (27 kB)\r\n",
      "Building wheels for collected packages: vector-quantize-pytorch, aim-ui, fire\r\n",
      "  Building wheel for vector-quantize-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for vector-quantize-pytorch: filename=vector_quantize_pytorch-0.1.0-py3-none-any.whl size=2555 sha256=52ddd0a4decbb93805d674ac9100526752bc53951c69f7fe9c951897ce26f339\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/bb/2a/ca39acc77ce55e2955c666ec690d1513386c00064b1373f7fe\r\n",
      "  Building wheel for aim-ui (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for aim-ui: filename=aim_ui-3.29.1-py3-none-any.whl size=31195131 sha256=90e9c8806d2f69ea5e8b10fa356a65d36a2ab7a7970d3bdbed3d5158b95e1200\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/67/57/0042ea0babc5e4a1359519783813304223c64653c0be9c7d74\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=9a773824245c61f63a0f005779deb519abb77fe3231e03f8693c068fcacda5ae\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\r\n",
      "Successfully built vector-quantize-pytorch aim-ui fire\r\n",
      "Installing collected packages: aimrocks, aim-ui, RestrictedPython, py, fire, base58, retry, aimrecords, vector-quantize-pytorch, contrastive_learner, aim, stylegan2_pytorch\r\n",
      "Successfully installed RestrictedPython-8.0 aim-3.29.1 aim-ui-3.29.1 aimrecords-0.0.7 aimrocks-0.5.2 base58-2.0.1 contrastive_learner-0.1.1 fire-0.7.0 py-1.11.0 retry-0.9.2 stylegan2_pytorch-1.9.0 vector-quantize-pytorch-0.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install stylegan2_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3559273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:37.970479Z",
     "iopub.status.busy": "2025-07-24T05:44:37.969745Z",
     "iopub.status.idle": "2025-07-24T05:44:40.995690Z",
     "shell.execute_reply": "2025-07-24T05:44:40.994879Z"
    },
    "papermill": {
     "duration": 3.06094,
     "end_time": "2025-07-24T05:44:40.997189",
     "exception": false,
     "start_time": "2025-07-24T05:44:37.936249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\r\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba3b595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:41.065001Z",
     "iopub.status.busy": "2025-07-24T05:44:41.064234Z",
     "iopub.status.idle": "2025-07-24T05:44:44.788549Z",
     "shell.execute_reply": "2025-07-24T05:44:44.787777Z"
    },
    "papermill": {
     "duration": 3.759502,
     "end_time": "2025-07-24T05:44:44.790358",
     "exception": false,
     "start_time": "2025-07-24T05:44:41.030856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan2'...\r\n",
      "remote: Enumerating objects: 138, done.\u001b[K\r\n",
      "remote: Total 138 (delta 0), reused 0 (delta 0), pack-reused 138 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (138/138), 594.93 KiB | 14.51 MiB/s, done.\r\n",
      "Resolving deltas: 100% (64/64), done.\r\n",
      "/kaggle/working/stylegan2\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2\n",
    "%cd stylegan2\n",
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168b7cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:44.857830Z",
     "iopub.status.busy": "2025-07-24T05:44:44.857577Z",
     "iopub.status.idle": "2025-07-24T05:44:48.201614Z",
     "shell.execute_reply": "2025-07-24T05:44:48.200883Z"
    },
    "papermill": {
     "duration": 3.378789,
     "end_time": "2025-07-24T05:44:48.203055",
     "exception": false,
     "start_time": "2025-07-24T05:44:44.824266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (8.2.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Collecting pyspng\r\n",
      "  Downloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\r\n",
      "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (0.6.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyspng) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pyspng) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pyspng) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pyspng) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pyspng) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pyspng) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pyspng) (2024.2.0)\r\n",
      "Downloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.1/196.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyspng\r\n",
      "Successfully installed pyspng-0.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install click requests tqdm pyspng ninja imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465d4356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:48.271853Z",
     "iopub.status.busy": "2025-07-24T05:44:48.271238Z",
     "iopub.status.idle": "2025-07-24T05:44:48.845862Z",
     "shell.execute_reply": "2025-07-24T05:44:48.845099Z"
    },
    "papermill": {
     "duration": 0.610112,
     "end_time": "2025-07-24T05:44:48.847329",
     "exception": false,
     "start_time": "2025-07-24T05:44:48.237217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan2-ada-pytorch'...\r\n",
      "remote: Enumerating objects: 131, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (2/2), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\r\n",
      "remote: Total 131 (delta 0), reused 0 (delta 0), pack-reused 129 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (131/131), 1.13 MiB | 22.26 MiB/s, done.\r\n",
      "Resolving deltas: 100% (57/57), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4b9fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:48.915898Z",
     "iopub.status.busy": "2025-07-24T05:44:48.915633Z",
     "iopub.status.idle": "2025-07-24T05:44:55.797078Z",
     "shell.execute_reply": "2025-07-24T05:44:55.795793Z"
    },
    "papermill": {
     "duration": 6.9173,
     "end_time": "2025-07-24T05:44:55.799137",
     "exception": false,
     "start_time": "2025-07-24T05:44:48.881837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-742hu3xc\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-742hu3xc\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting ftfy (from clip==1.0)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (25.0)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->clip==1.0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->clip==1.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->clip==1.0) (2024.2.0)\r\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=214e5ae5cf31b550eb17acb40fc9454b9b1a59855220d7a4981ed4fdd1e70fbf\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f31q9c9h/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: ftfy, clip\r\n",
      "Successfully installed clip-1.0 ftfy-6.3.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924d0509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:44:55.887959Z",
     "iopub.status.busy": "2025-07-24T05:44:55.887292Z",
     "iopub.status.idle": "2025-07-24T05:45:12.216039Z",
     "shell.execute_reply": "2025-07-24T05:45:12.214726Z"
    },
    "papermill": {
     "duration": 16.365114,
     "end_time": "2025-07-24T05:45:12.217486",
     "exception": false,
     "start_time": "2025-07-24T05:44:55.852372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-24 05:44:55--  https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl\r\n",
      "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 3.163.158.75, 3.163.158.83, 3.163.158.113, ...\r\n",
      "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|3.163.158.75|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 381673535 (364M) [application/x-www-form-urlencoded]\r\n",
      "Saving to: ‘stylegan2_ffhq.pkl’\r\n",
      "\r\n",
      "stylegan2_ffhq.pkl  100%[===================>] 363.99M  25.6MB/s    in 16s     \r\n",
      "\r\n",
      "2025-07-24 05:45:12 (23.4 MB/s) - ‘stylegan2_ffhq.pkl’ saved [381673535/381673535]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl -O stylegan2_ffhq.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434dc45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:45:12.291941Z",
     "iopub.status.busy": "2025-07-24T05:45:12.291639Z",
     "iopub.status.idle": "2025-07-24T05:45:12.608826Z",
     "shell.execute_reply": "2025-07-24T05:45:12.607797Z"
    },
    "papermill": {
     "duration": 0.355465,
     "end_time": "2025-07-24T05:45:12.610403",
     "exception": false,
     "start_time": "2025-07-24T05:45:12.254938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /kaggle/working/stylegan2\n",
    "!rm -rf /kaggle/working/stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6f9f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:45:12.687398Z",
     "iopub.status.busy": "2025-07-24T05:45:12.687085Z",
     "iopub.status.idle": "2025-07-24T05:45:12.820348Z",
     "shell.execute_reply": "2025-07-24T05:45:12.819338Z"
    },
    "papermill": {
     "duration": 0.174092,
     "end_time": "2025-07-24T05:45:12.821891",
     "exception": false,
     "start_time": "2025-07-24T05:45:12.647799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\r\n",
      "Cloning into '/kaggle/working/stylegan2-ada-pytorch'...\r\n",
      "fatal: Unable to read current working directory: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git /kaggle/working/stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007f742",
   "metadata": {
    "papermill": {
     "duration": 0.040108,
     "end_time": "2025-07-24T05:45:12.899863",
     "exception": false,
     "start_time": "2025-07-24T05:45:12.859755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ✅ 1: Setup + EEG Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55a157c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:45:12.999383Z",
     "iopub.status.busy": "2025-07-24T05:45:12.998792Z"
    },
    "papermill": {
     "duration": 3.052845,
     "end_time": "2025-07-24T05:45:16.002751",
     "exception": false,
     "start_time": "2025-07-24T05:45:12.949906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SYSTEM & UTILITIES ===\n",
    "import os                   # OS-level file operations\n",
    "import random               # Random number generation\n",
    "import gc                   # Garbage collector control\n",
    "import warnings             # Suppress warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "gc.collect()                       # Free unused memory\n",
    "\n",
    "# === NUMERIC & SCIENTIFIC COMPUTING ===\n",
    "import numpy as np                 # Numerical operations\n",
    "from scipy.signal import butter, lfilter, resample  # Signal processing (EEG)\n",
    "from sklearn.decomposition import FastICA           # ICA for artifact removal\n",
    "from sklearn.preprocessing import StandardScaler    # Normalization\n",
    "\n",
    "# === TORCH & TRAINING ===\n",
    "import torch                      # Core PyTorch\n",
    "import torch.nn as nn             # Neural network layers\n",
    "import torch.nn.functional as F   # Functional interface\n",
    "from torch.nn.functional import adaptive_avg_pool2d  # Adaptive pooling\n",
    "from tqdm import tqdm             # Training progress bar\n",
    "\n",
    "# === VISION & IMAGE TRANSFORMS ===\n",
    "from PIL import Image                                     # Image I/O\n",
    "from torchvision import transforms                        # Image transforms\n",
    "from torchvision.transforms import ToPILImage, Resize, Compose, ToTensor\n",
    "from torchvision.utils import save_image                  # Save generated images\n",
    "import matplotlib.pyplot as plt                           # Plotting\n",
    "import seaborn as sns                                     # Advanced plots\n",
    "\n",
    "# === IMAGE QUALITY & EVALUATION METRICS ===\n",
    "from skimage.metrics import structural_similarity as ssim  # SSIM metric\n",
    "from pytorch_msssim import ms_ssim                         # Multi-scale SSIM\n",
    "from torchvision.models import inception_v3                # InceptionV3 for FID\n",
    "\n",
    "# === GENERATIVE MODELS ===\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler  # Diffusion models\n",
    "from stylegan2_pytorch import ModelLoader                      # StyleGAN2 loader\n",
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/working/stylegan2-ada-pytorch\")\n",
    "import dnnlib, legacy                                          # StyleGAN2 legacy utils\n",
    "print(\"✅ dnnlib and legacy imported successfully.\")\n",
    "\n",
    "\n",
    "# === TEXT & CLIP MODELS ===\n",
    "import clip  # OpenAI CLIP for vision-language similarity\n",
    "\n",
    "# === DEVICE CLEANUP ===\n",
    "torch.cuda.empty_cache()  # Clear CUDA cache if used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea59ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:05:30.249124Z",
     "iopub.status.busy": "2025-07-24T05:05:30.248192Z",
     "iopub.status.idle": "2025-07-24T05:05:31.000400Z",
     "shell.execute_reply": "2025-07-24T05:05:30.999698Z",
     "shell.execute_reply.started": "2025-07-24T05:05:30.249096Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"  # No GPU or MPS support for SD\n",
    "\n",
    "# Set float32, not float16\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    torch_dtype=torch.float32\n",
    ").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939c357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:05:34.639454Z",
     "iopub.status.busy": "2025-07-24T05:05:34.639177Z",
     "iopub.status.idle": "2025-07-24T05:05:37.334931Z",
     "shell.execute_reply": "2025-07-24T05:05:37.334290Z",
     "shell.execute_reply.started": "2025-07-24T05:05:34.639436Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open(\"/kaggle/working/stylegan2_ffhq.pkl\", 'rb') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "G.eval()\n",
    "print(\"✅ G_ema done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28012b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ✅ 2: Load EEG-Labeled Sample + EEG2LatentNet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53679e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:05:42.296956Z",
     "iopub.status.busy": "2025-07-24T05:05:42.296341Z",
     "iopub.status.idle": "2025-07-24T05:06:24.845432Z",
     "shell.execute_reply": "2025-07-24T05:06:24.844786Z",
     "shell.execute_reply.started": "2025-07-24T05:05:42.296933Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eeg_data_path = \"/kaggle/input/eeg-imagenet/EEG-ImageNet_1.pth\"\n",
    "imagenet_base_dir = \"/kaggle/input/imagenet100\"\n",
    "\n",
    "# === Load EEG-labeled dataset ===\n",
    "print(\"🔄 Loading EEG-labeled dataset...\")\n",
    "eeg_dataset = torch.load(eeg_data_path, map_location=\"cpu\", weights_only=False)\n",
    "all_img_paths = eeg_dataset[\"images\"]\n",
    "print(f\"📂 Total EEG-image entries: {len(all_img_paths)}\")\n",
    "\n",
    "# === Find all ImageNet train.X* folders ===\n",
    "train_dirs = [os.path.join(imagenet_base_dir, d) for d in os.listdir(imagenet_base_dir)\n",
    "              if d.startswith(\"train.X\") and os.path.isdir(os.path.join(imagenet_base_dir, d))]\n",
    "\n",
    "print(\"📁 Using the following training folders:\")\n",
    "for d in train_dirs:\n",
    "    print(\"   -\", d)\n",
    "\n",
    "# === Get available WNIDs ===\n",
    "available_wnids = set()\n",
    "for train_dir in train_dirs:\n",
    "    for wnid in os.listdir(train_dir):\n",
    "        full_path = os.path.join(train_dir, wnid)\n",
    "        if os.path.isdir(full_path):\n",
    "            available_wnids.add(wnid)\n",
    "\n",
    "# === Match EEG-image pairs ===\n",
    "valid_entries = []\n",
    "not_found = 0\n",
    "for idx, rel_path in enumerate(all_img_paths):\n",
    "    wnid = rel_path.split(\"/\")[0] if \"/\" in rel_path else rel_path.split(\"_\")[0]\n",
    "    inner_path = rel_path if \"/\" in rel_path else os.path.join(wnid, rel_path)\n",
    "    if wnid not in available_wnids:\n",
    "        continue\n",
    "    for train_dir in train_dirs:\n",
    "        full_path = os.path.join(train_dir, inner_path)\n",
    "        if os.path.exists(full_path):\n",
    "            valid_entries.append((idx, full_path))\n",
    "            break\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(f\"✅ Total valid EEG-image pairs: {len(valid_entries)}\")\n",
    "print(f\"❌ Missing or not found: {not_found}\")\n",
    "print(f\"📊 Total EEG-image entries: {len(all_img_paths)}\")\n",
    "\n",
    "# === Select and extract EEG-data ===\n",
    "index, img_path = random.choice(valid_entries)\n",
    "eeg_data = eeg_dataset['dataset'][index]\n",
    "label_text = eeg_data.get('label', 'Unknown') if isinstance(eeg_data, dict) else 'Unknown'\n",
    "\n",
    "# === Extract EEG tensor ===\n",
    "if isinstance(eeg_data, dict):\n",
    "    if 'eeg_data' in eeg_data and isinstance(eeg_data['eeg_data'], torch.Tensor):\n",
    "        eeg_tensor = eeg_data['eeg_data']\n",
    "    else:\n",
    "        raise ValueError(\"❌ No tensor field 'eeg_data' found.\")\n",
    "elif isinstance(eeg_data, torch.Tensor):\n",
    "    eeg_tensor = eeg_data\n",
    "else:\n",
    "    raise TypeError(f\"❌ Unexpected EEG data type: {type(eeg_data)}\")\n",
    "\n",
    "# === Load image ===\n",
    "img_real = Image.open(img_path).convert(\"RGB\").resize((512, 512))\n",
    "prompt = f\"A photo of a {label_text}\"\n",
    "\n",
    "# === Final info ===\n",
    "print(f\"🧠 EEG tensor shape: {eeg_tensor.shape}\")\n",
    "print(f\"🖼️ Matched image: {os.path.basename(img_path)}\")\n",
    "print(f\"📸 Prompt: {prompt}\")\n",
    "\n",
    "\n",
    "print(\"EEG tensor shape:\", eeg_tensor.shape)\n",
    "\n",
    "if eeg_tensor.ndim == 1:\n",
    "    print(\"❌ EEG tensor has no time axis (only one value per channel). You need time series per channel.\")\n",
    "elif eeg_tensor.ndim == 2:\n",
    "    print(\"✅ EEG tensor is shaped correctly:\", eeg_tensor.shape)\n",
    "    print(\"▶️ EEG preview (first 5 channels, 10 samples):\")\n",
    "    print(eeg_tensor[:5, :10])\n",
    "else:\n",
    "    print(\"⚠️ Unexpected shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e9074",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📦 3: EEG Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd7ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:30.934130Z",
     "iopub.status.busy": "2025-07-24T05:06:30.933450Z",
     "iopub.status.idle": "2025-07-24T05:06:30.938290Z",
     "shell.execute_reply": "2025-07-24T05:06:30.937642Z",
     "shell.execute_reply.started": "2025-07-24T05:06:30.934103Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"eeg_tensor shape:\", eeg_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793be27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:35.798650Z",
     "iopub.status.busy": "2025-07-24T05:06:35.798376Z",
     "iopub.status.idle": "2025-07-24T05:06:35.808166Z",
     "shell.execute_reply": "2025-07-24T05:06:35.807438Z",
     "shell.execute_reply.started": "2025-07-24T05:06:35.798631Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ Fixed EEGPreprocessor with robust segment() method\n",
    "class EEGPreprocessor:\n",
    "    def __init__(self, fs=512, target_fs=128, window_size=128):\n",
    "        self.fs = fs\n",
    "        self.target_fs = target_fs\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def bandpass(self, eeg, lowcut=0.5, highcut=45, order=5):\n",
    "        nyq = 0.5 * self.fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return lfilter(b, a, eeg, axis=-1)\n",
    "\n",
    "    def remove_artifacts(self, eeg, n_components=10):\n",
    "        ica = FastICA(n_components=min(n_components, eeg.shape[0]), random_state=0, max_iter=300)\n",
    "        try:\n",
    "            eeg_ica = ica.fit_transform(eeg.T).T\n",
    "            eeg_ica[np.abs(eeg_ica) > 5 * np.std(eeg_ica)] = 0\n",
    "            return eeg_ica\n",
    "        except Exception:\n",
    "            return eeg\n",
    "\n",
    "    def downsample(self, eeg):\n",
    "        factor = self.fs // self.target_fs\n",
    "        return resample(eeg, eeg.shape[-1] // factor, axis=-1)\n",
    "\n",
    "    def zscore(self, eeg):\n",
    "        scaler = StandardScaler()\n",
    "        shape = eeg.shape\n",
    "        eeg_flat = eeg.reshape(shape[0], -1)\n",
    "        eeg_norm = scaler.fit_transform(eeg_flat)\n",
    "        return eeg_norm.reshape(shape)\n",
    "\n",
    "    def segment(self, eeg):\n",
    "        # EEG input shape: (channels, samples) or (1, channels, samples)\n",
    "        if eeg.ndim == 3:\n",
    "            eeg = eeg[0]  # Remove batch dimension\n",
    "\n",
    "        if eeg.ndim != 2:\n",
    "            raise ValueError(f\"Expected shape (channels, samples), got {eeg.shape}\")\n",
    "\n",
    "        num_channels, num_samples = eeg.shape\n",
    "\n",
    "        if num_samples < self.window_size:\n",
    "            padded = np.zeros((num_channels, self.window_size))\n",
    "            padded[:, :num_samples] = eeg\n",
    "            return np.stack([padded])\n",
    "\n",
    "        segments = []\n",
    "        for start in range(0, num_samples - self.window_size + 1, self.window_size):\n",
    "            segments.append(eeg[:, start:start + self.window_size])\n",
    "        return np.stack(segments)\n",
    "\n",
    "    def aggregate(self, segments):\n",
    "        return np.mean(segments, axis=0, keepdims=True)  # Shape: (1, channels, window_size)\n",
    "\n",
    "    def __call__(self, eeg):\n",
    "        eeg = self.bandpass(eeg)\n",
    "        eeg = self.remove_artifacts(eeg)\n",
    "        eeg = self.downsample(eeg)\n",
    "        eeg = self.zscore(eeg)\n",
    "        segments = self.segment(eeg)\n",
    "        return self.aggregate(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9b5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:40.861823Z",
     "iopub.status.busy": "2025-07-24T05:06:40.861564Z",
     "iopub.status.idle": "2025-07-24T05:06:41.082846Z",
     "shell.execute_reply": "2025-07-24T05:06:41.082053Z",
     "shell.execute_reply.started": "2025-07-24T05:06:40.861806Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary dimensions to get shape [channels, samples]\n",
    "eeg_np = eeg_tensor.detach().cpu().numpy()\n",
    "\n",
    "# Continuously squeeze the array until only 2D remains (channels × samples)\n",
    "while eeg_np.ndim > 2:\n",
    "    eeg_np = eeg_np[0]\n",
    "\n",
    "print(\"➡️ EEG input to preprocessor:\", eeg_np.shape)  # Expected: (10, 128)\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = EEGPreprocessor()\n",
    "\n",
    "# Run preprocessing: bandpass, ICA, downsampling, z-score, segmentation, aggregation\n",
    "eeg_tensor_preprocessed = preprocessor(eeg_np)\n",
    "\n",
    "print(\"✅ Preprocessed EEG shape:\", eeg_tensor_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c719e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:45.633848Z",
     "iopub.status.busy": "2025-07-24T05:06:45.633559Z",
     "iopub.status.idle": "2025-07-24T05:06:45.792060Z",
     "shell.execute_reply": "2025-07-24T05:06:45.791318Z",
     "shell.execute_reply.started": "2025-07-24T05:06:45.633826Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = EEGPreprocessor()\n",
    "eeg_tensor_preprocessed = preprocessor(eeg_tensor.numpy())\n",
    "print(\"✅ Preprocessed EEG shape:\", eeg_tensor_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf314a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧠 4. EEG2LatentNet: EEG → Z_EEG (Latent vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d4737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:52.099161Z",
     "iopub.status.busy": "2025-07-24T05:06:52.098853Z",
     "iopub.status.idle": "2025-07-24T05:06:52.106102Z",
     "shell.execute_reply": "2025-07-24T05:06:52.105296Z",
     "shell.execute_reply.started": "2025-07-24T05:06:52.099141Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === EEG → Latent Encoder ===\n",
    "\n",
    "class EEG2LatentNet(nn.Module):\n",
    "    def __init__(self, in_chans=10, samples=128, latent_dim=512):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Dummy pass to get flattened shape\n",
    "        dummy = torch.zeros(1, 1, in_chans, samples)\n",
    "        dummy = self.forward_conv(dummy)\n",
    "        self.flattened_dim = dummy.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc = nn.Linear(self.flattened_dim, latent_dim)\n",
    "\n",
    "    def forward_conv(self, x):\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        x = F.elu(self.bn2(self.conv2(x)))\n",
    "        x = F.elu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e940005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:56.229680Z",
     "iopub.status.busy": "2025-07-24T05:06:56.229427Z",
     "iopub.status.idle": "2025-07-24T05:06:56.286481Z",
     "shell.execute_reply": "2025-07-24T05:06:56.285866Z",
     "shell.execute_reply.started": "2025-07-24T05:06:56.229665Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EEG2LatentNet(in_chans=eeg_tensor_preprocessed.shape[1],\n",
    "                      samples=eeg_tensor_preprocessed.shape[2])\n",
    "\n",
    "eeg_input = torch.tensor(eeg_tensor_preprocessed).unsqueeze(0).float()  # → [1, 1, 10, 128]\n",
    "latent = model(eeg_input)\n",
    "print(\"🧠 EEG latent shape:\", latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c212d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:06:59.484177Z",
     "iopub.status.busy": "2025-07-24T05:06:59.483871Z",
     "iopub.status.idle": "2025-07-24T05:06:59.488582Z",
     "shell.execute_reply": "2025-07-24T05:06:59.487715Z",
     "shell.execute_reply.started": "2025-07-24T05:06:59.484154Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape after preprocessing:\", eeg_tensor_preprocessed.shape)  #  [1, 10, 128]\n",
    "print(\"Shape after unsqueeze:\", eeg_input.shape)  #  [1, 1, 10, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f178b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎨 5. Stable Diffusion: Inversion and Decoding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde0ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:07:03.441605Z",
     "iopub.status.busy": "2025-07-24T05:07:03.441331Z",
     "iopub.status.idle": "2025-07-24T05:07:03.448200Z",
     "shell.execute_reply": "2025-07-24T05:07:03.447468Z",
     "shell.execute_reply.started": "2025-07-24T05:07:03.441585Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Invert real image → latent vector ===\n",
    "def ddim_invert(pipe, image, prompt, device=\"cuda\"):\n",
    "    # Set DDIM scheduler (for deterministic latent mapping)\n",
    "    scheduler = DDIMScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")\n",
    "    pipe.scheduler = scheduler\n",
    "    pipe.to(device)\n",
    "\n",
    "    # Resize and convert image\n",
    "    image = image.resize((512, 512))\n",
    "    image_tensor = pipe.feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    image_tensor = image_tensor.to(dtype=pipe.vae.dtype)\n",
    "\n",
    "    # Encode image to latent using VAE\n",
    "    with torch.no_grad():\n",
    "        latents = pipe.vae.encode(image_tensor * 2 - 1).latent_dist.sample() * 0.18215\n",
    "        # Ensure correct latent resolution\n",
    "        if latents.shape[-1] != 64:\n",
    "            latents = F.interpolate(latents, size=(64, 64), mode='bilinear')\n",
    "\n",
    "    return latents  # Shape: [1, 4, 64, 64]\n",
    "\n",
    "\n",
    "def decode_latent(pipe, latent):\n",
    "    with torch.no_grad():\n",
    "        latent = latent.to(dtype=pipe.vae.dtype)\n",
    "        image = pipe.vae.decode(latent / 0.18215).sample\n",
    "        image = (image / 2 + 0.5).clamp(0, 1)  # Convert from [-1, 1] to [0, 1]\n",
    "        image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        return Image.fromarray(image)  # ← Return as PIL.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ce9f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. StyleGAN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43607ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:07:10.610028Z",
     "iopub.status.busy": "2025-07-24T05:07:10.609397Z",
     "iopub.status.idle": "2025-07-24T05:07:10.614091Z",
     "shell.execute_reply": "2025-07-24T05:07:10.613318Z",
     "shell.execute_reply.started": "2025-07-24T05:07:10.609989Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#=== Download the pretrained StyleGAN2-ADA model if not already downloaded ===\n",
    "pkl_path = \"stylegan2_ffhq.pkl\"\n",
    "if not os.path.exists(pkl_path):\n",
    "    !wget https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl -O stylegan2_ffhq.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176e406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:13:22.181324Z",
     "iopub.status.busy": "2025-07-24T05:13:22.180994Z",
     "iopub.status.idle": "2025-07-24T05:14:09.140645Z",
     "shell.execute_reply": "2025-07-24T05:14:09.139974Z",
     "shell.execute_reply.started": "2025-07-24T05:13:22.181303Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Load the generator (G_ema) from the .pkl file ===\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)  # G_ema = pretrained generator\n",
    "\n",
    "G.eval()\n",
    "print(\"✅ StyleGAN2 model loaded.\")\n",
    "\n",
    "# === Step 1: Load StyleGAN2-ADA Generator ===\n",
    "with open(\"stylegan2_ffhq.pkl\", \"rb\") as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "G.eval()\n",
    "\n",
    "# === Step 2: Prepare latent vector and empty conditioning label ===\n",
    "z = torch.randn(1, G.z_dim).to(device)    # Latent vector z ∈ ℝ^512\n",
    "c = torch.zeros([1, G.c_dim]).to(device)  # Empty label vector c ∈ ℝ^0\n",
    "\n",
    "# === Step 3: Generate image ===\n",
    "with torch.no_grad():\n",
    "     image_stylegan = G(z, c, truncation_psi=0.7, noise_mode='const')[0]\n",
    "\n",
    "# === Step 4: Normalize and save image ===\n",
    "image_stylegan = (image_stylegan + 1) / 2  # Convert from [-1, 1] to [0, 1] for display\n",
    "save_image(image_stylegan, \"generated_image_stylegan2.png\")\n",
    "print(\"✅ Image saved as 'generated_image_stylegan2.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d86fb4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🚂 7. Supervised Training: EEG → Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee383f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-24T05:04:18.660Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd3bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:07:23.588478Z",
     "iopub.status.busy": "2025-07-24T05:07:23.588144Z",
     "iopub.status.idle": "2025-07-24T05:07:23.593458Z",
     "shell.execute_reply": "2025-07-24T05:07:23.592571Z",
     "shell.execute_reply.started": "2025-07-24T05:07:23.588454Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"eeg_tensor.shape:\", eeg_tensor.shape)\n",
    "print(\"Total elements:\", eeg_tensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cefd1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:07:27.232594Z",
     "iopub.status.busy": "2025-07-24T05:07:27.232313Z",
     "iopub.status.idle": "2025-07-24T05:07:27.381458Z",
     "shell.execute_reply": "2025-07-24T05:07:27.380638Z",
     "shell.execute_reply.started": "2025-07-24T05:07:27.232574Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess EEG data (e.g. shape: [10, 128])\n",
    "eeg_tensor_preprocessed = preprocessor(eeg_tensor.cpu().numpy())\n",
    "\n",
    "# Wrap into torch tensor with shape [1, 1, 10, 128]\n",
    "eeg_tensor_input = torch.tensor(eeg_tensor_preprocessed).unsqueeze(0).float().to(device)\n",
    "\n",
    "print(\"Final input to EEG2LatentNet:\", eeg_tensor_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c788e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:07:32.839126Z",
     "iopub.status.busy": "2025-07-24T05:07:32.838497Z",
     "iopub.status.idle": "2025-07-24T05:07:56.538649Z",
     "shell.execute_reply": "2025-07-24T05:07:56.537937Z",
     "shell.execute_reply.started": "2025-07-24T05:07:32.839096Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Initialize EEG → Latent model ===\n",
    "eeg2latent = EEG2LatentNet(\n",
    "    in_chans=eeg_tensor_input.shape[2],\n",
    "    samples=eeg_tensor_input.shape[3],\n",
    "    latent_dim=16384  # Match latent size for Stable Diffusion (4×64×64)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(eeg2latent.parameters(), lr=1e-3)\n",
    "\n",
    "# === Load Stable Diffusion ===\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16\n",
    ").to(device)\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# === Invert real image into SD latent ===\n",
    "latent_real = ddim_invert(pipe, img_real, prompt, device=device)\n",
    "\n",
    "# === Train EEG2LatentNet with MSE loss ===\n",
    "for step in range(100):\n",
    "    pred_latent = eeg2latent(eeg_tensor_input)\n",
    "    loss = F.mse_loss(pred_latent, latent_real.view(1, -1).float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step:03d} | Latent MSE Loss: {loss.item():.6f}\")\n",
    "\n",
    "# === After training, reshape predicted latent for decoding ===\n",
    "pred_latent = eeg2latent(eeg_tensor_input).view(1, 4, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29633cef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧪 7. Inference: Generate Image from EEG and Compare with Ground Truth\n",
    "\n",
    "This block uses the trained EEG2LatentNet to generate an image from EEG input, then compares it to the real image using MS-SSIM and CLIP similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260bc9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:08:13.457127Z",
     "iopub.status.busy": "2025-07-24T05:08:13.456780Z",
     "iopub.status.idle": "2025-07-24T05:08:20.548423Z",
     "shell.execute_reply": "2025-07-24T05:08:20.547710Z",
     "shell.execute_reply.started": "2025-07-24T05:08:13.457106Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Load CLIP model and move to device ===\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81225b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:08:30.576710Z",
     "iopub.status.busy": "2025-07-24T05:08:30.576410Z",
     "iopub.status.idle": "2025-07-24T05:08:30.580626Z",
     "shell.execute_reply": "2025-07-24T05:08:30.580068Z",
     "shell.execute_reply.started": "2025-07-24T05:08:30.576690Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # This is CLIP's required input size\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a65791",
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-24T05:04:18.661Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69635fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:15:43.715654Z",
     "iopub.status.busy": "2025-07-24T05:15:43.715314Z",
     "iopub.status.idle": "2025-07-24T05:23:08.474837Z",
     "shell.execute_reply": "2025-07-24T05:23:08.473901Z",
     "shell.execute_reply.started": "2025-07-24T05:15:43.715630Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Make sure models are on correct device\n",
    "eeg2latent = eeg2latent.to(device)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "pipe = pipe.to(\"cpu\") \n",
    "prompt = \"A futuristic cityscape, sunset, cyberpunk style\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(\"sd_output.png\")\n",
    "\n",
    "eeg2latent.eval()\n",
    "\n",
    "# Ensure correct EEG input shape\n",
    "if eeg_tensor_input.ndim == 4:\n",
    "    eeg_tensor_input = eeg_tensor_input.unsqueeze(2)\n",
    "\n",
    "assert eeg_tensor_input.shape == (1, 1, 1, 10, 128), f\"Unexpected EEG shape: {eeg_tensor_input.shape}\"\n",
    "\n",
    "# Load pipeline for CPU (without float16!)\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "pipe = pipe.to(\"cpu\")\n",
    "\n",
    "# Speed up generation\n",
    "pipe.scheduler = DDIMScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")\n",
    "pipe.scheduler.set_timesteps(20)\n",
    "\n",
    "# === Decode latent vector into image\n",
    "\n",
    "# === Fix shape of latent vector before decoding\n",
    "if pred_latent.shape == (1, 16384):\n",
    "    pred_latent = pred_latent.view(1, 4, 64, 64)\n",
    "elif pred_latent.ndim != 4:\n",
    "    raise ValueError(f\"❌ Unexpected latent shape: {pred_latent.shape}\")\n",
    "\n",
    "\n",
    "def decode_latent(pipe, latent, device=\"cuda\"):\n",
    "    pipe.vae = pipe.vae.to(device)  \n",
    "    with torch.no_grad():\n",
    "        latent = latent.to(dtype=pipe.vae.dtype, device=device)\n",
    "        image = pipe.vae.decode(latent / 0.18215).sample\n",
    "        image = (image / 2 + 0.5).clamp(0, 1)\n",
    "        image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        return Image.fromarray(image)\n",
    "\n",
    "img_gen = decode_latent(pipe, pred_latent, device=device)\n",
    "\n",
    "\n",
    "\n",
    "# === (Optional) show/save\n",
    "img_gen.show()\n",
    "img_gen.save(\"generated_from_eeg.png\")\n",
    "\n",
    "# === Prepare transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# === Make sure img_real exists\n",
    "assert 'img_real' in globals(), \"img_real not defined!\"\n",
    "img_real_tensor = transform(img_real).unsqueeze(0).to(device)\n",
    "img_gen_tensor = transform(img_gen).unsqueeze(0).to(device)\n",
    "\n",
    "# === MS-SSIM\n",
    "ms_score = ms_ssim(img_real_tensor, img_gen_tensor, data_range=1.0, size_average=True)\n",
    "print(f\"📊 MS-SSIM: {ms_score.item():.4f}\")\n",
    "\n",
    "# === CLIP Cosine Similarity\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "with torch.no_grad():\n",
    "    z_real = clip_model.encode_image(img_real_tensor).float()\n",
    "    z_gen = clip_model.encode_image(img_gen_tensor).float()\n",
    "    z_real = z_real / z_real.norm(dim=-1, keepdim=True)\n",
    "    z_gen = z_gen / z_gen.norm(dim=-1, keepdim=True)\n",
    "    sim_score = (z_real @ z_gen.T).item()\n",
    "print(f\"🧠 CLIP Cosine Similarity: {sim_score:.4f}\")\n",
    "\n",
    "# === 📷 Plot results\n",
    "\n",
    "# == Enlarged EEG (top) + Bigger Real and Generated Images (bottom) ===\n",
    "fig = plt.figure(figsize=(14, 10))  \n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[3, 4])  # EEG выше\n",
    "\n",
    "# EEG Plot (top row, full width)\n",
    "ax_eeg = fig.add_subplot(gs[0, :])\n",
    "eeg_np = eeg_tensor_input.squeeze().cpu().numpy()  # shape: [10, 128]\n",
    "for i in range(min(5, eeg_np.shape[0])):\n",
    "    ax_eeg.plot(eeg_np[i] + i * 10, label=f\"Ch {i}\")\n",
    "ax_eeg.set_title(\"📈 EEG Signal (first 5 channels)\", fontsize=14)\n",
    "ax_eeg.set_xlabel(\"Time\", fontsize=12)\n",
    "ax_eeg.set_ylabel(\"Amplitude\", fontsize=12)\n",
    "ax_eeg.grid(True)\n",
    "\n",
    "# Ground Truth Image (bottom left)\n",
    "ax_real = fig.add_subplot(gs[1, 0])\n",
    "ax_real.imshow(img_real.resize((320, 320)))  \n",
    "ax_real.set_title(f\"🟢 Ground Truth\\nLabel: {label_text}\", fontsize=14)\n",
    "ax_real.axis(\"off\")\n",
    "\n",
    "# Generated Image (bottom right)\n",
    "ax_gen = fig.add_subplot(gs[1, 1])\n",
    "ax_gen.imshow(img_gen.resize((320, 320)))  \n",
    "ax_gen.set_title(f\"🧠 Generated\\nMS-SSIM: {ms_score.item():.4f}\\nCLIP: {sim_score:.4f}\", fontsize=14)\n",
    "ax_gen.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"🧪 EEG → Real Image → Generated Image\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca370b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:25:08.268648Z",
     "iopub.status.busy": "2025-07-24T05:25:08.267791Z",
     "iopub.status.idle": "2025-07-24T05:25:08.834174Z",
     "shell.execute_reply": "2025-07-24T05:25:08.833325Z",
     "shell.execute_reply.started": "2025-07-24T05:25:08.268622Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === EEG INPUT (shape: [1, 1, 10, 128]) ===\n",
    "eeg_np = eeg_tensor_input.squeeze().cpu().numpy()  # shape: [10, 128]\n",
    "\n",
    "# === Generated Image (StyleGAN2 output) ===\n",
    "# 'image' is a tensor from GAN: shape [3, H, W], values in [0, 1]\n",
    "img_gen = image \n",
    "\n",
    "# === Real image if available ===\n",
    "# Otherwise use placeholder\n",
    "try:\n",
    "    img_real_resized = img_real.resize((320, 320))\n",
    "except:\n",
    "    img_real_resized = Image.new(\"RGB\", (320, 320), color=\"gray\")\n",
    "    label_text = \"Unknown\"\n",
    "\n",
    "# === Plot ===\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[3, 4])\n",
    "\n",
    "# EEG Plot (top row, full width)\n",
    "ax_eeg = fig.add_subplot(gs[0, :])\n",
    "for i in range(min(5, eeg_np.shape[0])):\n",
    "    ax_eeg.plot(eeg_np[i] + i * 10, label=f\"Ch {i}\")\n",
    "ax_eeg.set_title(\"📈 EEG Signal (first 5 channels)\", fontsize=14)\n",
    "ax_eeg.set_xlabel(\"Time\", fontsize=12)\n",
    "ax_eeg.set_ylabel(\"Amplitude\", fontsize=12)\n",
    "ax_eeg.grid(True)\n",
    "\n",
    "# Ground Truth Image (bottom left)\n",
    "ax_real = fig.add_subplot(gs[1, 0])\n",
    "ax_real.imshow(img_real_resized)\n",
    "ax_real.set_title(f\"🟢 Ground Truth\\nLabel: {label_text}\", fontsize=14)\n",
    "ax_real.axis(\"off\")\n",
    "\n",
    "# Generated Image (bottom right)\n",
    "ax_gen = fig.add_subplot(gs[1, 1])\n",
    "ax_gen.imshow(img_gen.resize((320, 320)))\n",
    "ax_gen.set_title(\"🧠 Generated by StyleGAN2\", fontsize=14)\n",
    "ax_gen.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"🧪 EEG → Real Image → StyleGAN2 Generated Image\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a86a67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7356fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:33:42.394804Z",
     "iopub.status.busy": "2025-07-24T05:33:42.394234Z",
     "iopub.status.idle": "2025-07-24T05:33:49.827114Z",
     "shell.execute_reply": "2025-07-24T05:33:49.825892Z",
     "shell.execute_reply.started": "2025-07-24T05:33:42.394778Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Prepare preprocessing for FID ===\n",
    "fid_transform = Compose([Resize((299, 299)), ToTensor()])\n",
    "\n",
    "def get_inception_features(img_tensor):\n",
    "    # Image tensor: shape [1, 3, H, W], values in [0, 1]\n",
    "    model = inception_v3(pretrained=True, transform_input=False).eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        img_resized = F.interpolate(img_tensor, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        pred = model(img_resized)\n",
    "        pooled = adaptive_avg_pool2d(pred.unsqueeze(0), output_size=(1, 1)).squeeze()\n",
    "    return pooled\n",
    "\n",
    "def calculate_fid(feat1, feat2):\n",
    "    # Both inputs are torch tensors\n",
    "    mu1, mu2 = feat1.mean(), feat2.mean()\n",
    "    sigma1, sigma2 = torch.var(feat1), torch.var(feat2)\n",
    "    fid = (mu1 - mu2).pow(2) + sigma1 + sigma2 - 2 * torch.sqrt(sigma1 * sigma2)\n",
    "    return fid.item()\n",
    "\n",
    "# === CLIP MODEL ===\n",
    "clip_model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def clip_similarity(img1, img2):\n",
    "    img1_prep = preprocess_clip(img1).unsqueeze(0).to(device)\n",
    "    img2_prep = preprocess_clip(img2).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat1 = clip_model.encode_image(img1_prep)\n",
    "        feat2 = clip_model.encode_image(img2_prep)\n",
    "    return F.cosine_similarity(feat1, feat2).item()\n",
    "\n",
    "# === MS-SSIM ===\n",
    "def compute_ms_ssim(img1, img2):\n",
    "    # Ensure RGB and same size\n",
    "    img1 = img1.convert(\"RGB\").resize((256, 256))\n",
    "    img2 = img2.convert(\"RGB\").resize((256, 256))\n",
    "\n",
    "    img1_np = np.array(img1).astype(np.float32) / 255.0\n",
    "    img2_np = np.array(img2).astype(np.float32) / 255.0\n",
    "\n",
    "    return ssim(img1_np, img2_np, channel_axis=-1, win_size=7, data_range=1.0)\n",
    "\n",
    "# === Convert StyleGAN2/SD output to PIL ===\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "target_size = (256, 256)\n",
    "\n",
    "img_stylegan = img_stylegan.resize(target_size)\n",
    "img_gen = img_gen.resize(target_size)\n",
    "img_gt = img_real.resize(target_size)\n",
    "\n",
    "\n",
    "# === Metrics ===\n",
    "ms_score_sg = compute_ms_ssim(img_stylegan, img_gt)\n",
    "ms_score_sd = compute_ms_ssim(img_gen, img_gt)\n",
    "\n",
    "clip_score_sg = clip_similarity(img_stylegan, img_gt)\n",
    "clip_score_sd = clip_similarity(img_gen, img_gt)\n",
    "\n",
    "feat_sg = get_inception_features(ToTensor()(img_stylegan).unsqueeze(0).to(device))\n",
    "feat_sd = get_inception_features(ToTensor()(img_gen).unsqueeze(0).to(device))\n",
    "feat_gt = get_inception_features(ToTensor()(img_gt).unsqueeze(0).to(device))\n",
    "\n",
    "fid_sg = calculate_fid(feat_sg, feat_gt)\n",
    "fid_sd = calculate_fid(feat_sd, feat_gt)\n",
    "\n",
    "# === Plotting ===\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(2, 3, height_ratios=[3, 4])\n",
    "\n",
    "# EEG Plot\n",
    "ax_eeg = fig.add_subplot(gs[0, :])\n",
    "eeg_np = eeg_tensor_input.squeeze().cpu().numpy()\n",
    "for i in range(min(5, eeg_np.shape[0])):\n",
    "    ax_eeg.plot(eeg_np[i] + i * 10, label=f\"Ch {i}\")\n",
    "ax_eeg.set_title(\"📈 EEG Signal (first 5 channels)\", fontsize=14)\n",
    "ax_eeg.set_xlabel(\"Time\", fontsize=12)\n",
    "ax_eeg.set_ylabel(\"Amplitude\", fontsize=12)\n",
    "ax_eeg.grid(True)\n",
    "\n",
    "# Ground Truth\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax1.imshow(img_gt)\n",
    "ax1.set_title(\"🟢 Ground Truth\", fontsize=14)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# StyleGAN2\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "ax2.imshow(img_stylegan)\n",
    "ax2.set_title(f\"🎨 StyleGAN2\\nMS-SSIM: {ms_score_sg:.3f}\\nCLIP: {clip_score_sg:.3f}\\nFID: {fid_sg:.2f}\", fontsize=14)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "# StableDiffusion\n",
    "ax3 = fig.add_subplot(gs[1, 2])\n",
    "ax3.imshow(img_gen)\n",
    "ax3.set_title(f\"🌀 Stable Diffusion\\nMS-SSIM: {ms_score_sd:.3f}\\nCLIP: {clip_score_sd:.3f}\\nFID: {fid_sd:.2f}\", fontsize=14)\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"🧪 EEG → Image Comparison (StyleGAN2 vs Stable Diffusion)\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da413104",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧠 8. Semi-Supervised Inference: EEGs Without Labels (Unlabeled Subset)\n",
    "\n",
    "This block demonstrates how to apply the trained model on unlabeled EEG data, simulating the semi-supervised setup where labels or paired images are unavailable. We skip metrics but still generate images from EEG alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5c768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T05:36:09.776159Z",
     "iopub.status.busy": "2025-07-24T05:36:09.775484Z",
     "iopub.status.idle": "2025-07-24T05:36:25.514932Z",
     "shell.execute_reply": "2025-07-24T05:36:25.514135Z",
     "shell.execute_reply.started": "2025-07-24T05:36:09.776130Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Semi-Supervised Inference on Unlabeled EEG ===\n",
    "unlabeled_start = len(eeg_dataset['images'])\n",
    "unlabeled_end = len(eeg_dataset['dataset'])\n",
    "\n",
    "unlabeled_index = random.randint(unlabeled_start, unlabeled_end - 1)\n",
    "eeg_unlabeled = eeg_dataset['dataset'][unlabeled_index]\n",
    "\n",
    "# === Handle dict type ===\n",
    "if isinstance(eeg_unlabeled, dict):\n",
    "    if 'eeg_data' in eeg_unlabeled:\n",
    "        eeg_unlabeled = eeg_unlabeled['eeg_data']\n",
    "    else:\n",
    "        raise ValueError(\"❌ No 'eeg_data' found in unlabeled entry.\")\n",
    "\n",
    "print(\"📐 EEG shape before preprocessing:\", eeg_unlabeled.shape)\n",
    "\n",
    "# === Preprocess and generate image ===\n",
    "eeg_segments_unlabeled = preprocessor(eeg_unlabeled)\n",
    "eeg_tensor_unlabeled = torch.tensor(eeg_segments_unlabeled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    latent_pred_unlabeled = eeg2latent(eeg_tensor_unlabeled)\n",
    "    latent_pred_unlabeled = latent_pred_unlabeled.view(1, 4, 64, 64)\n",
    "    img_generated_unlabeled = decode_latent(pipe, latent_pred_unlabeled)\n",
    "\n",
    "# === Show EEG and generated image ===\n",
    "def plot_eeg_heatmap(eeg_array, title=\"Unlabeled EEG\"):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(eeg_array[0], aspect='auto', cmap='plasma', interpolation='nearest')\n",
    "    plt.colorbar(label=\"Amplitude\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Channels\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# === EEG Line Plot: Unlabeled EEG (first 5 channels) ===\n",
    "def plot_eeg_lines(eeg_array, title=\"Unlabeled EEG Signal (first 5 channels)\"):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(min(5, eeg_array.shape[1])):\n",
    "        plt.plot(eeg_array[0][i] + i * 10)  # offset each channel for clarity\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_eeg_lines(eeg_segments_unlabeled, title=\"🧠 Unlabeled EEG Signal (first 5 channels)\")\n",
    "plot_eeg_heatmap(eeg_segments_unlabeled, title=\"🧠 Unlabeled EEG Signal\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img_generated_unlabeled)\n",
    "plt.title(\"🧠 Generated Image from Unlabeled EEG\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 341166,
     "sourceId": 675926,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1500837,
     "sourceId": 2491748,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7783012,
     "sourceId": 12345866,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 228.981597,
   "end_time": "2025-07-24T05:45:16.042419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-24T05:41:27.060822",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
